{
  "event_sourcing_patterns": {
    "title": "Event Sourcing Architecture Patterns",
    "content": "Event Sourcing is an architectural pattern where all changes to application state are stored as a sequence of events. Instead of storing just the current state of the data in a domain, event sourcing stores all events that led to the current state.\n\n**Core Concepts:**\n\n1. **Event Store**: A persistent storage mechanism that stores all events in chronological order. Events are immutable once stored.\n\n2. **Event Streams**: Logical groupings of events, typically organized by aggregate root or entity.\n\n3. **Snapshots**: Periodic captures of aggregate state to optimize replay performance for long event streams.\n\n4. **Projections**: Read models built by replaying events, optimized for specific query patterns.\n\n**Implementation Patterns:**\n\n**Command-Event Separation:**\n```\nCommand → Aggregate → Events → Event Store\n                   ↓\n              Event Handlers → Read Models\n```\n\n**Event Schema Evolution:**\n- Additive changes: Add new optional fields\n- Transformative changes: Use event upcasting\n- Breaking changes: Create new event versions\n\n**Aggregate Design:**\n- Keep aggregates small and focused\n- Ensure aggregate boundaries align with transaction boundaries\n- Use correlation IDs to track related events across aggregates\n\n**Event Ordering:**\n- Global ordering: Single event stream with total ordering\n- Aggregate ordering: Ordering within aggregate boundaries\n- Causal ordering: Preserve causality relationships\n\n**Example - E-commerce Order Management:**\n\n```json\n{\n  \"eventType\": \"OrderCreated\",\n  \"aggregateId\": \"order-12345\",\n  \"version\": 1,\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"data\": {\n    \"customerId\": \"cust-789\",\n    \"items\": [\n      {\"productId\": \"prod-456\", \"quantity\": 2, \"price\": 29.99}\n    ],\n    \"totalAmount\": 59.98,\n    \"currency\": \"USD\"\n  }\n}\n\n{\n  \"eventType\": \"PaymentProcessed\",\n  \"aggregateId\": \"order-12345\",\n  \"version\": 2,\n  \"timestamp\": \"2024-01-15T10:31:30Z\",\n  \"data\": {\n    \"paymentId\": \"pay-999\",\n    \"amount\": 59.98,\n    \"method\": \"credit_card\",\n    \"status\": \"approved\"\n  }\n}\n\n{\n  \"eventType\": \"OrderShipped\",\n  \"aggregateId\": \"order-12345\",\n  \"version\": 3,\n  \"timestamp\": \"2024-01-16T14:20:00Z\",\n  \"data\": {\n    \"shippingId\": \"ship-777\",\n    \"carrier\": \"UPS\",\n    \"trackingNumber\": \"1Z999AA1234567890\",\n    \"estimatedDelivery\": \"2024-01-18T18:00:00Z\"\n  }\n}\n```\n\n**Benefits:**\n- Complete audit trail\n- Temporal queries (state at any point in time)\n- Natural fit for event-driven architectures\n- Debugging and analytics capabilities\n- Scalable read models\n\n**Challenges:**\n- Event schema evolution complexity\n- Storage requirements grow over time\n- Learning curve for developers\n- Eventual consistency in read models\n- Replay performance for long streams\n\n**Best Practices:**\n\n1. **Design Events Carefully**: Events should represent business facts, not technical implementation details\n\n2. **Version Events**: Plan for schema evolution from the beginning\n\n3. **Optimize for Replay**: Use snapshots and efficient serialization\n\n4. **Handle Failures**: Implement idempotent event handlers and dead letter queues\n\n5. **Monitor Event Streams**: Track event processing lag and error rates\n\n6. **Test Event Evolution**: Verify that new code can handle old events\n\n**Technology Considerations:**\n\n- **Event Stores**: EventStore, Apache Kafka, Amazon Kinesis, Azure Event Hubs\n- **Serialization**: Avro, Protocol Buffers, JSON with schema validation\n- **Processing**: Apache Flink, Kafka Streams, Azure Stream Analytics\n- **Storage**: Optimized for append-only workloads, consider partitioning strategies\n\nEvent sourcing works particularly well for domains with complex business logic, regulatory requirements for audit trails, and systems that need to support temporal queries or analytics on historical data."
  },
  
  "microservices_saga_patterns": {
    "title": "Saga Patterns in Microservices",
    "content": "The Saga pattern is a design pattern for managing distributed transactions across multiple microservices. Instead of traditional two-phase commit protocols, sagas use a sequence of local transactions with compensating actions.\n\n**Core Concepts:**\n\n1. **Choreography-based Saga**: Services communicate directly through events, with each service listening for events and deciding what to do next.\n\n2. **Orchestration-based Saga**: A central coordinator (saga orchestrator) manages the transaction flow and tells each service what to do.\n\n**Choreography Pattern:**\n```\nOrder Service → Payment Service → Inventory Service → Shipping Service\n     ↓              ↓                ↓               ↓\nOrderCreated → PaymentProcessed → InventoryReserved → OrderShipped\n```\n\n**Orchestration Pattern:**\n```\n        Saga Orchestrator\n           /    |    \\\n    Order Svc Payment Svc Inventory Svc\n```\n\n**Implementation Example - E-commerce Order Processing:**\n\n**Choreography Approach:**\n\n1. **Order Service**: Creates order, publishes OrderCreated event\n2. **Payment Service**: Processes payment, publishes PaymentProcessed event\n3. **Inventory Service**: Reserves items, publishes InventoryReserved event\n4. **Shipping Service**: Arranges shipping, publishes OrderShipped event\n\n**Compensation Logic:**\n- If payment fails → Cancel order\n- If inventory unavailable → Refund payment, cancel order\n- If shipping fails → Release inventory, refund payment, cancel order\n\n**Orchestration Approach:**\n\n```python\nclass OrderSagaOrchestrator:\n    def process_order(self, order):\n        try:\n            # Step 1: Validate order\n            self.order_service.validate_order(order)\n            \n            # Step 2: Process payment\n            payment_result = self.payment_service.process_payment(\n                order.customer_id, order.total_amount\n            )\n            \n            # Step 3: Reserve inventory\n            inventory_result = self.inventory_service.reserve_items(\n                order.items\n            )\n            \n            # Step 4: Arrange shipping\n            shipping_result = self.shipping_service.create_shipment(\n                order.shipping_address, order.items\n            )\n            \n            # Step 5: Confirm order\n            self.order_service.confirm_order(order.id)\n            \n        except Exception as e:\n            # Execute compensation actions in reverse order\n            self.compensate(order, e)\n    \n    def compensate(self, order, error):\n        # Compensate in reverse order\n        if hasattr(order, 'shipping_id'):\n            self.shipping_service.cancel_shipment(order.shipping_id)\n        \n        if hasattr(order, 'reservation_id'):\n            self.inventory_service.release_reservation(order.reservation_id)\n        \n        if hasattr(order, 'payment_id'):\n            self.payment_service.refund_payment(order.payment_id)\n        \n        self.order_service.cancel_order(order.id, str(error))\n```\n\n**Saga State Management:**\n\n```json\n{\n  \"sagaId\": \"saga-12345\",\n  \"orderIds\": \"order-67890\",\n  \"currentStep\": \"processing_payment\",\n  \"steps\": [\n    {\n      \"stepName\": \"validate_order\",\n      \"status\": \"completed\",\n      \"timestamp\": \"2024-01-15T10:30:00Z\"\n    },\n    {\n      \"stepName\": \"process_payment\",\n      \"status\": \"in_progress\",\n      \"timestamp\": \"2024-01-15T10:30:30Z\",\n      \"retryCount\": 1\n    }\n  ],\n  \"compensationActions\": [\n    {\n      \"action\": \"cancel_order\",\n      \"condition\": \"any_step_fails\"\n    }\n  ]\n}\n```\n\n**Error Handling Strategies:**\n\n1. **Retry with Exponential Backoff**: For transient failures\n2. **Circuit Breaker**: Prevent cascade failures\n3. **Timeout Handling**: Avoid indefinite waits\n4. **Dead Letter Queue**: Handle permanently failed messages\n5. **Manual Intervention**: For complex error scenarios\n\n**Comparison with Two-Phase Commit:**\n\n**Saga Advantages:**\n- Better availability (no locks)\n- Better performance (local transactions)\n- Scales horizontally\n- Resilient to service failures\n\n**Two-Phase Commit Advantages:**\n- ACID guarantees\n- Consistency is immediate\n- Simpler to reason about\n\n**Saga Disadvantages:**\n- Eventual consistency\n- Complex error handling\n- Potential for partial failures\n- Requires careful design of compensating actions\n\n**Best Practices:**\n\n1. **Design Idempotent Operations**: All saga steps should be safely retryable\n\n2. **Implement Proper Monitoring**: Track saga progress and failure rates\n\n3. **Use Correlation IDs**: Track related events across services\n\n4. **Design Compensating Actions Carefully**: Ensure they can undo business effects\n\n5. **Handle Partial Failures**: Plan for scenarios where compensation itself fails\n\n6. **Use Saga Timeout**: Set reasonable timeouts for long-running sagas\n\n7. **Implement Saga Recovery**: Handle saga orchestrator failures\n\n**Technology Stack Examples:**\n\n- **Event Streaming**: Apache Kafka, Amazon Kinesis\n- **Orchestration**: Netflix Conductor, Uber Cadence, Temporal\n- **State Management**: Redis, MongoDB, PostgreSQL\n- **Monitoring**: Distributed tracing with Jaeger or Zipkin"
  }
}