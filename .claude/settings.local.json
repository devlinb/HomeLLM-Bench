{
  "permissions": {
    "allow": [
      "Bash(python:*)",
      "Bash(huggingface-cli download:*)",
      "Bash(nvidia-smi:*)",
      "Bash(fuser:*)",
      "Bash(curl:*)",
      "Bash(pkill:*)",
      "Bash(true)",
      "Bash(kill:*)",
      "Bash(rm:*)",
      "WebFetch(domain:huggingface.co)",
      "WebFetch(domain:docs.vllm.ai)",
      "Bash(timeout:*)",
      "Bash(ls:*)",
      "Bash(grep:*)",
      "Bash(mkdir:*)",
      "Bash(cp:*)",
      "Bash(mv:*)",
      "Bash(chmod:*)",
      "Bash(find:*)",
      "Bash(./homellm-benchmark:*)",
      "Bash(./homellm-server --help)",
      "Bash(./homellm-server:*)",
      "Bash(git add:*)",
      "Bash(ss:*)",
      "Bash(pip install:*)",
      "WebFetch(domain:docs.flashinfer.ai)",
      "Bash(nvcc:*)",
      "Bash(env)",
      "Bash(export:*)",
      "Bash(export VLLM_ATTENTION_BACKEND=FLASHINFER)",
      "Bash(/venv/main/bin/python3 /venv/main/bin/vllm serve Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4 --max-model-len 8192 --enforce-eager --download-dir /workspace/models --host 127.0.0.1 --port 8002 --tensor-parallel-size 2)",
      "WebFetch(domain:github.com)",
      "Bash(ollama list:*)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(git clone:*)",
      "Bash(pip uninstall:*)",
      "Bash(apt-get:*)",
      "Bash(apt-get install:*)",
      "Bash(sudo apt-get:*)",
      "Bash(sudo apt-get install:*)",
      "Bash(f5-tts_infer-gradio:*)"
    ],
    "deny": []
  }
}